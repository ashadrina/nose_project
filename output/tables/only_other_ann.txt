initial data:  (36, 8, 121)
initial data:  (4, 8, 121)
initial data:  (75, 8, 121)
(15, 968)
(75, 968)
Training model...
Epoch 1/100
0s - loss: 3.1264 - acc: 0.0000e+00
Epoch 2/100
0s - loss: 2.8763 - acc: 0.0667
Epoch 3/100
0s - loss: 2.7393 - acc: 0.0667
Epoch 4/100
0s - loss: 2.7127 - acc: 0.0667
Epoch 5/100
0s - loss: 2.6478 - acc: 0.1333
Epoch 6/100
0s - loss: 2.6064 - acc: 0.2000
Epoch 7/100
0s - loss: 2.4753 - acc: 0.3333
Epoch 8/100
0s - loss: 2.4589 - acc: 0.1333
Epoch 9/100
0s - loss: 2.3032 - acc: 0.6000
Epoch 10/100
0s - loss: 2.3821 - acc: 0.2000
Epoch 11/100
0s - loss: 2.1654 - acc: 0.5333
Epoch 12/100
0s - loss: 2.1694 - acc: 0.5333
Epoch 13/100
0s - loss: 2.4201 - acc: 0.3333
Epoch 14/100
0s - loss: 2.0822 - acc: 0.6667
Epoch 15/100
0s - loss: 2.0792 - acc: 0.6000
Epoch 16/100
0s - loss: 2.1454 - acc: 0.3333
Epoch 17/100
0s - loss: 2.1374 - acc: 0.4000
Epoch 18/100
0s - loss: 2.0261 - acc: 0.5333
Epoch 19/100
0s - loss: 2.0385 - acc: 0.7333
Epoch 20/100
0s - loss: 2.1080 - acc: 0.5333
Epoch 21/100
0s - loss: 1.9589 - acc: 0.6667
Epoch 22/100
0s - loss: 1.8940 - acc: 0.8000
Epoch 23/100
0s - loss: 1.9416 - acc: 0.7333
Epoch 24/100
0s - loss: 1.9484 - acc: 0.7333
Epoch 25/100
0s - loss: 1.8188 - acc: 0.8000
Epoch 26/100
0s - loss: 1.9276 - acc: 0.6000
Epoch 27/100
0s - loss: 1.9383 - acc: 0.5333
Epoch 28/100
0s - loss: 1.9319 - acc: 0.7333
Epoch 29/100
0s - loss: 1.6579 - acc: 1.0000
Epoch 30/100
0s - loss: 1.7184 - acc: 0.7333
Epoch 31/100
0s - loss: 1.7825 - acc: 0.8000
Epoch 32/100
0s - loss: 1.6862 - acc: 0.8000
Epoch 33/100
0s - loss: 1.6591 - acc: 0.8000
Epoch 34/100
0s - loss: 1.6187 - acc: 0.8667
Epoch 35/100
0s - loss: 1.4979 - acc: 1.0000
Epoch 36/100
0s - loss: 1.4510 - acc: 1.0000
Epoch 37/100
0s - loss: 1.6267 - acc: 0.8000
Epoch 38/100
0s - loss: 1.7051 - acc: 0.8667
Epoch 39/100
0s - loss: 1.4702 - acc: 0.8667
Epoch 40/100
0s - loss: 1.6110 - acc: 0.7333
Epoch 41/100
0s - loss: 1.6659 - acc: 0.7333
Epoch 42/100
0s - loss: 1.5138 - acc: 0.9333
Epoch 43/100
0s - loss: 1.4446 - acc: 0.9333
Epoch 44/100
0s - loss: 1.5277 - acc: 0.8667
Epoch 45/100
0s - loss: 1.4864 - acc: 0.9333
Epoch 46/100
0s - loss: 1.3436 - acc: 0.8000
Epoch 47/100
0s - loss: 1.3328 - acc: 0.9333
Epoch 48/100
0s - loss: 1.6380 - acc: 0.7333
Epoch 49/100
0s - loss: 1.3704 - acc: 0.8667
Epoch 50/100
0s - loss: 1.3765 - acc: 1.0000
Epoch 51/100
0s - loss: 1.3231 - acc: 1.0000
Epoch 52/100
0s - loss: 1.3601 - acc: 0.9333
Epoch 53/100
0s - loss: 1.2406 - acc: 0.9333
Epoch 54/100
0s - loss: 1.3194 - acc: 0.9333
Epoch 55/100
0s - loss: 1.3284 - acc: 1.0000
Epoch 56/100
0s - loss: 1.2201 - acc: 0.9333
Epoch 57/100
0s - loss: 1.2690 - acc: 0.9333
Epoch 58/100
0s - loss: 1.2606 - acc: 1.0000
Epoch 59/100
0s - loss: 1.1788 - acc: 1.0000
Epoch 60/100
0s - loss: 1.3054 - acc: 1.0000
Epoch 61/100
0s - loss: 1.0872 - acc: 1.0000
Epoch 62/100
0s - loss: 1.2048 - acc: 1.0000
Epoch 63/100
0s - loss: 1.2252 - acc: 1.0000
Epoch 64/100
0s - loss: 1.2520 - acc: 1.0000
Epoch 65/100
0s - loss: 1.3092 - acc: 0.9333
Epoch 66/100
0s - loss: 1.2409 - acc: 1.0000
Epoch 67/100
0s - loss: 1.1894 - acc: 0.9333
Epoch 68/100
0s - loss: 1.0865 - acc: 0.9333
Epoch 69/100
0s - loss: 1.1562 - acc: 1.0000
Epoch 70/100
0s - loss: 1.3084 - acc: 0.9333
Epoch 71/100
0s - loss: 1.1940 - acc: 1.0000
Epoch 72/100
0s - loss: 1.1372 - acc: 0.9333
Epoch 73/100
0s - loss: 1.1410 - acc: 1.0000
Epoch 74/100
0s - loss: 1.1306 - acc: 0.9333
Epoch 75/100
0s - loss: 1.1688 - acc: 0.9333
Epoch 76/100
0s - loss: 1.1861 - acc: 1.0000
Epoch 77/100
0s - loss: 1.1129 - acc: 1.0000
Epoch 78/100
0s - loss: 1.0433 - acc: 1.0000
Epoch 79/100
0s - loss: 1.1559 - acc: 0.9333
Epoch 80/100
0s - loss: 1.1423 - acc: 1.0000
Epoch 81/100
0s - loss: 1.0292 - acc: 1.0000
Epoch 82/100
0s - loss: 1.0190 - acc: 0.9333
Epoch 83/100
0s - loss: 0.9739 - acc: 1.0000
Epoch 84/100
0s - loss: 0.9527 - acc: 1.0000
Epoch 85/100
0s - loss: 0.9398 - acc: 1.0000
Epoch 86/100
0s - loss: 1.1106 - acc: 1.0000
Epoch 87/100
0s - loss: 0.9506 - acc: 1.0000
Epoch 88/100
0s - loss: 0.9233 - acc: 1.0000
Epoch 89/100
0s - loss: 1.0112 - acc: 1.0000
Epoch 90/100
0s - loss: 1.0448 - acc: 1.0000
Epoch 91/100
0s - loss: 0.8819 - acc: 1.0000
Epoch 92/100
0s - loss: 1.1045 - acc: 1.0000
Epoch 93/100
0s - loss: 0.9150 - acc: 1.0000
Epoch 94/100
0s - loss: 0.9346 - acc: 1.0000
Epoch 95/100
0s - loss: 1.0094 - acc: 1.0000
Epoch 96/100
0s - loss: 0.9117 - acc: 0.9333
Epoch 97/100
0s - loss: 0.9975 - acc: 1.0000
Epoch 98/100
0s - loss: 1.0254 - acc: 0.9333
Epoch 99/100
0s - loss: 0.9901 - acc: 1.0000
Epoch 100/100
0s - loss: 0.9486 - acc: 1.0000
15/15 [==============================] - 0s
Training model... DONE
Train score: 1.0, loss: 0.683594922225
32/75 [===========>..................] - ETA: 0s64/75 [========================>.....] - ETA: 0s75/75 [==============================] - 0s     
['benzin' 'butanol' 'butilazetat' 'dioktilftalat_with_azetaldegid'
 'dioktilftalat_with_azeton' 'dioktilftalat_with_benzol'
 'dioktilftalat_with_etilazetat' 'fenol' 'geksan' 'izobutanol'
 'izopropanol' 'other' 'propanol' 'stirol' 'toluol']
['benzin' 'butanol' 'butilazetat' 'dioktilftalat_with_azetaldegid'
 'dioktilftalat_with_azeton' 'dioktilftalat_with_benzol'
 'dioktilftalat_with_etilazetat' 'fenol' 'geksan' 'izobutanol'
 'izopropanol' 'other' 'propanol' 'stirol' 'toluol']
['benzin' 'butanol' 'butilazetat' 'dioktilftalat_with_azetaldegid'
 'dioktilftalat_with_azeton' 'dioktilftalat_with_benzol'
 'dioktilftalat_with_etilazetat' 'fenol' 'geksan' 'izobutanol'
 'izopropanol' 'other' 'propanol' 'stirol' 'toluol']
You should predict top  1.0  labels for train
You should predict top  10.08  labels for toys
label_ranking_average_precision_score on train 1.0
label_ranking_average_precision_score on toys 0.260877474377
Compiling LSTM model...
Compiling LSTM model... DONE
Preparing data...
(15, 5, 968) (15, 15) (75, 5, 968)
Training LSTM model...
Epoch 1/1
0s - loss: 0.7635 - acc: 0.0667
Epoch 1/1
0s - loss: 0.7311 - acc: 0.0000e+00
Epoch 1/1
0s - loss: 0.7382 - acc: 0.1333
Epoch 1/1
0s - loss: 0.7696 - acc: 0.1333
Epoch 1/1
0s - loss: 0.7281 - acc: 0.0000e+00
Epoch 1/1
0s - loss: 0.7323 - acc: 0.0000e+00
Epoch 1/1
0s - loss: 0.7099 - acc: 0.1333
Epoch 1/1
0s - loss: 0.6557 - acc: 0.1333
Epoch 1/1
0s - loss: 0.7208 - acc: 0.0000e+00
Epoch 1/1
0s - loss: 0.6969 - acc: 0.0000e+00
Epoch 1/1
0s - loss: 0.7199 - acc: 0.0000e+00
Epoch 1/1
0s - loss: 0.6789 - acc: 0.0667
Epoch 1/1
0s - loss: 0.7152 - acc: 0.1333
Epoch 1/1
0s - loss: 0.7219 - acc: 0.0000e+00
Epoch 1/1
0s - loss: 0.6507 - acc: 0.1333
Epoch 1/1
0s - loss: 0.6973 - acc: 0.1333
Epoch 1/1
0s - loss: 0.6982 - acc: 0.0000e+00
Epoch 1/1
0s - loss: 0.6986 - acc: 0.1333
Epoch 1/1
0s - loss: 0.6678 - acc: 0.0000e+00
Epoch 1/1
0s - loss: 0.6641 - acc: 0.0667
Epoch 1/1
0s - loss: 0.6557 - acc: 0.1333
Epoch 1/1
0s - loss: 0.6809 - acc: 0.0000e+00
Epoch 1/1
0s - loss: 0.6495 - acc: 0.1333
Epoch 1/1
0s - loss: 0.6466 - acc: 0.0000e+00
Epoch 1/1
0s - loss: 0.6430 - acc: 0.0667
Epoch 1/1
0s - loss: 0.6450 - acc: 0.2667
Epoch 1/1
0s - loss: 0.6715 - acc: 0.2000
Epoch 1/1
0s - loss: 0.6244 - acc: 0.0667
Epoch 1/1
0s - loss: 0.6351 - acc: 0.0000e+00
Epoch 1/1
0s - loss: 0.6000 - acc: 0.0667
Epoch 1/1
0s - loss: 0.6303 - acc: 0.0667
Epoch 1/1
0s - loss: 0.6001 - acc: 0.0667
Epoch 1/1
0s - loss: 0.6417 - acc: 0.0000e+00
Epoch 1/1
0s - loss: 0.6132 - acc: 0.1333
Epoch 1/1
0s - loss: 0.5969 - acc: 0.1333
Epoch 1/1
0s - loss: 0.5916 - acc: 0.2000
Epoch 1/1
0s - loss: 0.5947 - acc: 0.0667
Epoch 1/1
0s - loss: 0.6078 - acc: 0.0667
Epoch 1/1
0s - loss: 0.5896 - acc: 0.0000e+00
Epoch 1/1
0s - loss: 0.5639 - acc: 0.2667
Epoch 1/1
0s - loss: 0.5294 - acc: 0.2000
Epoch 1/1
0s - loss: 0.5438 - acc: 0.0667
Epoch 1/1
0s - loss: 0.5795 - acc: 0.0000e+00
Epoch 1/1
0s - loss: 0.5601 - acc: 0.0667
Epoch 1/1
0s - loss: 0.5740 - acc: 0.2667
Epoch 1/1
0s - loss: 0.5505 - acc: 0.2000
Epoch 1/1
0s - loss: 0.5078 - acc: 0.5333
Epoch 1/1
0s - loss: 0.4855 - acc: 0.2667
Epoch 1/1
0s - loss: 0.4930 - acc: 0.1333
Epoch 1/1
0s - loss: 0.5310 - acc: 0.0667
Epoch 1/1
0s - loss: 0.4858 - acc: 0.1333
Epoch 1/1
0s - loss: 0.4647 - acc: 0.4000
Epoch 1/1
0s - loss: 0.4861 - acc: 0.2000
Epoch 1/1
0s - loss: 0.4181 - acc: 0.1333
Epoch 1/1
0s - loss: 0.4756 - acc: 0.1333
Epoch 1/1
0s - loss: 0.4421 - acc: 0.1333
Epoch 1/1
0s - loss: 0.4634 - acc: 0.1333
Epoch 1/1
0s - loss: 0.4409 - acc: 0.1333
Epoch 1/1
0s - loss: 0.4306 - acc: 0.2000
Epoch 1/1
0s - loss: 0.4629 - acc: 0.1333
Epoch 1/1
0s - loss: 0.3972 - acc: 0.1333
Epoch 1/1
0s - loss: 0.4728 - acc: 0.0000e+00
Epoch 1/1
0s - loss: 0.3802 - acc: 0.3333
Epoch 1/1
0s - loss: 0.4232 - acc: 0.3333
Epoch 1/1
0s - loss: 0.4004 - acc: 0.0000e+00
Epoch 1/1
0s - loss: 0.3773 - acc: 0.1333
Epoch 1/1
0s - loss: 0.3946 - acc: 0.2667
Epoch 1/1
0s - loss: 0.3879 - acc: 0.1333
Epoch 1/1
0s - loss: 0.3717 - acc: 0.0667
Epoch 1/1
0s - loss: 0.3718 - acc: 0.2000
Epoch 1/1
0s - loss: 0.3142 - acc: 0.2667
Epoch 1/1
0s - loss: 0.3320 - acc: 0.3333
Epoch 1/1
0s - loss: 0.3658 - acc: 0.0667
Epoch 1/1
0s - loss: 0.3147 - acc: 0.2667
Epoch 1/1
0s - loss: 0.3253 - acc: 0.1333
Epoch 1/1
0s - loss: 0.2879 - acc: 0.3333
Epoch 1/1
0s - loss: 0.2661 - acc: 0.2667
Epoch 1/1
0s - loss: 0.3172 - acc: 0.1333
Epoch 1/1
0s - loss: 0.3151 - acc: 0.2000
Epoch 1/1
0s - loss: 0.2723 - acc: 0.1333
Epoch 1/1
0s - loss: 0.2699 - acc: 0.2667
Epoch 1/1
0s - loss: 0.2712 - acc: 0.0667
Epoch 1/1
0s - loss: 0.2358 - acc: 0.6000
Epoch 1/1
0s - loss: 0.2917 - acc: 0.0667
Epoch 1/1
0s - loss: 0.2457 - acc: 0.4000
Epoch 1/1
0s - loss: 0.2940 - acc: 0.0667
Epoch 1/1
0s - loss: 0.2503 - acc: 0.2667
Epoch 1/1
0s - loss: 0.2780 - acc: 0.2667
Epoch 1/1
0s - loss: 0.2759 - acc: 0.0667
Epoch 1/1
0s - loss: 0.2313 - acc: 0.4000
Epoch 1/1
0s - loss: 0.2482 - acc: 0.1333
Epoch 1/1
0s - loss: 0.2597 - acc: 0.2000
Epoch 1/1
0s - loss: 0.2565 - acc: 0.2000
Epoch 1/1
0s - loss: 0.2550 - acc: 0.2000
Epoch 1/1
0s - loss: 0.2320 - acc: 0.3333
Epoch 1/1
0s - loss: 0.2681 - acc: 0.2000
Epoch 1/1
0s - loss: 0.2454 - acc: 0.2667
Epoch 1/1
0s - loss: 0.2293 - acc: 0.2667
Epoch 1/1
0s - loss: 0.2409 - acc: 0.2667
Epoch 1/1
0s - loss: 0.2469 - acc: 0.2000
Training LSTM model... DONE
Train score: 0.466666673621, loss: 0.238733882705
 5/15 [=========>....................] - ETA: 0s10/15 [===================>..........] - ETA: 0s15/15 [==============================] - 0s     
 5/75 [=>............................] - ETA: 0s10/75 [===>..........................] - ETA: 0s15/75 [=====>........................] - ETA: 0s20/75 [=======>......................] - ETA: 0s25/75 [=========>....................] - ETA: 0s30/75 [===========>..................] - ETA: 0s35/75 [=============>................] - ETA: 0s40/75 [===============>..............] - ETA: 0s45/75 [=================>............] - ETA: 0s50/75 [===================>..........] - ETA: 0s55/75 [=====================>........] - ETA: 0s60/75 [=======================>......] - ETA: 0s65/75 [=========================>....] - ETA: 0s70/75 [===========================>..] - ETA: 0s75/75 [==============================] - 0s     
['benzin' 'butanol' 'butilazetat' 'dioktilftalat_with_azetaldegid'
 'dioktilftalat_with_azeton' 'dioktilftalat_with_benzol'
 'dioktilftalat_with_etilazetat' 'fenol' 'geksan' 'izobutanol'
 'izopropanol' 'other' 'propanol' 'stirol' 'toluol']
['benzin' 'butanol' 'butilazetat' 'dioktilftalat_with_azetaldegid'
 'dioktilftalat_with_azeton' 'dioktilftalat_with_benzol'
 'dioktilftalat_with_etilazetat' 'fenol' 'geksan' 'izobutanol'
 'izopropanol' 'other' 'propanol' 'stirol' 'toluol']
['benzin' 'butanol' 'butilazetat' 'dioktilftalat_with_azetaldegid'
 'dioktilftalat_with_azeton' 'dioktilftalat_with_benzol'
 'dioktilftalat_with_etilazetat' 'fenol' 'geksan' 'izobutanol'
 'izopropanol' 'other' 'propanol' 'stirol' 'toluol']
You should predict top  8.46666666667  labels for train
You should predict top  10.2133333333  labels for toys
label_ranking_average_precision_score on train 0.502222222222
label_ranking_average_precision_score on toys 0.178424161641
